---
title:  "What do dimensions of GAN capture? per-dimensional latent traversal on a GAN trained on DomainNet"
date: 2023-10-27
---

As a part of [this project](https://github.com/hamedrq7/Unsupervised-Visual-Feature-Learning-with-DCGAN-and-AE), which was homework for my neural network course at university, I trained deep convolutional GAN on CIFAR10 and mammals of the REAL domain of the DomainNet dataset.
Here are some images produced by the GAN: 
<p align="center" width="100%">
	<img width="95%" src="/assets/posts/latent/GAN%20mammals%20real%20and%20fake.png">
	<img width="95%" src="/assets/posts/latent/cifar%20real%20and fake%20images.png">
</p>
I must say, the fake images that the model generated are actually quite impressive! At first glance, they can easily deceive me into thinking that they are real images, but only if I take off my glasses :). The overall structure and arrangement of the photos produced by the model are so similar to those of the original dataset that if you place a 10x10 image grid of the fake images beside another 10x10 grid of the original dataset, it's hard to tell them apart! The reason for this is that the color and background schemes of the fake images are quite similar to those of the real images. In other words, the model can create detailed images by simply learning the color and background schemes of the original ones.

I also attempted to train a GAN using the CLIPART domain of the DomainNet dataset, which had a simpler domain with mostly a white background and cartoonish images. This time, the model is unable to fool me even at first glance, as the main distinguishing factor in this domain is the details rather than the background, and the model is unable to produce rich and meaningful details.
<p align="center" width="100%">
    <img width="95%" src="/assets/posts/latent/clipart real and fake images.png">
</p>

While I was doing this project, I was also reading the MMVAE paper. While going through the paper, I came across a figure that showed "per-dimension latent traversal." Since the VAE latent space is regularized by KL, it made sense to choose a dimension and observe the output of different values of the dimension. However, there is no regularization of the input latent space of GANs. Despite this, I wanted to see if I could identify a meaningful dimension that could alter a specific feature. 

To do this, I examined some generated images and picked out the more significant ones. After that, I tracked the noise fed to the model to produce the images. Then, I traversed through each dimension (by some step) while keeping the other dimensions fixed to see what different output it produces. Some of the dimensions were interesting and had a small degree of significance. 
<p align="center" width="100%">
	<img width="40%" src="/assets/posts/latent/12.jpg">
	<img width="40%" src="/assets/posts/latent/27.jpg">
</p>
In the left image, the selected dimension primarily affects the background, while the right image primarily affects the main object and its angle (the middle ones looks like a Cat). Keep in mind that these are just my speculations and the dimensions are far from being perpendicular to each other.
